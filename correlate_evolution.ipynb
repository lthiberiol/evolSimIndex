{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.odr              import Model, Data, RealData, ODR\n",
    "from scipy.stats            import linregress\n",
    "from scipy.optimize         import curve_fit\n",
    "from scipy.spatial.distance import squareform\n",
    "from matplotlib             import pyplot as plt\n",
    "from sklearn.linear_model   import HuberRegressor\n",
    "from copy                   import deepcopy\n",
    "from collections            import Counter\n",
    "from scipy.stats            import pearsonr\n",
    "from io import BytesIO\n",
    "\n",
    "import igraph     as ig\n",
    "import numpy      as np\n",
    "import seaborn    as sns\n",
    "import pandas     as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import ete3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class cd:\n",
    "    \"\"\"\n",
    "    Context manager for changing the current working directory\n",
    "    \"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cles(lessers, greaters):\n",
    "    \"\"\"Common-Language Effect Size\n",
    "    Probability that a random draw from `greater` is in fact greater\n",
    "    than a random draw from `lesser`.\n",
    "    Args:\n",
    "      lesser, greater: Iterables of comparables.\n",
    "      \n",
    "      https://github.com/ajschumacher/cles/blob/master/cles.py\n",
    "    \"\"\"\n",
    "    if len(lessers) == 0 and len(greaters) == 0:\n",
    "        raise ValueError('At least one argument must be non-empty')\n",
    "    # These values are a bit arbitrary, but make some sense.\n",
    "    # (It might be appropriate to warn for these cases.)\n",
    "    if len(lessers) == 0:\n",
    "        return 1\n",
    "    if len(greaters) == 0:\n",
    "        return 0\n",
    "    numerator = 0\n",
    "    lessers, greaters = sorted(lessers), sorted(greaters)\n",
    "    lesser_index = 0\n",
    "    for greater in greaters:\n",
    "        while lesser_index < len(lessers) and lessers[lesser_index] < greater:\n",
    "            lesser_index += 1\n",
    "        numerator += lesser_index  # the count less than the greater\n",
    "    denominator = len(lessers) * len(greaters)\n",
    "    return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def line(x, slope):\n",
    "    \"\"\"Basic linear regression 'model'\"\"\"\n",
    "    return (slope * x) + 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic wODR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_odr(x, y, x_weights, y_weights):\n",
    "    mod = Model(line)\n",
    "    dat = Data(x, \n",
    "               y, \n",
    "               wd=x_weights, \n",
    "               we=y_weights\n",
    "    )\n",
    "    odr = ODR(dat, \n",
    "              mod,\n",
    "              beta0=[np.std(y)/np.std(x)])\n",
    "    return(odr.run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary wODR weight estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def estimate_weights(x, y, weight_estimation='gm'):\n",
    "    if weight_estimation == 'gm':\n",
    "        slope = np.std(y)/np.std(x)\n",
    "        x_res = abs(x - line(y, \n",
    "                             slope))\n",
    "        y_res = abs(y - line(x, \n",
    "                             slope))\n",
    "\n",
    "    elif weight_estimation == 'huber':\n",
    "        huber_xy  = HuberRegressor(fit_intercept=False).fit(x.reshape(-1, 1), y)\n",
    "        huber_yx  = HuberRegressor(fit_intercept=False).fit(y.reshape(-1, 1), x)\n",
    "\n",
    "        y_res     = abs(y - line(x, \n",
    "                                 huber_xy.coef_))\n",
    "\n",
    "        x_res     = abs(x - line(y, \n",
    "                                 huber_yx.coef_))\n",
    "        \n",
    "    elif weight_estimation == 'ols':\n",
    "        xy_params = curve_fit(line, x, y)\n",
    "        y_res     = abs(y - line(x, \n",
    "                                 xy_params[0]))\n",
    "        \n",
    "        yx_params = curve_fit(line, y, x)\n",
    "        x_res     = abs(x - line(y, \n",
    "                                 yx_params[0]))\n",
    "    else:\n",
    "        raise Exception('weight_estimation must be \"gm\", \"huber\", or \"ols\"')\n",
    "\n",
    "    #\n",
    "    # if residuals are equal do zero it drives the weight to infinity,\n",
    "    #     and it is good practice not weigh things infinitely\n",
    "    x_res[x_res==0] = 1e-10\n",
    "    y_res[y_res==0] = 1e-10\n",
    "    return(1/abs(x_res), \n",
    "           1/abs(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from \".mldist\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_matrix(aln_file=None):\n",
    "        \n",
    "    dist_matrix = pd.read_csv(aln_file, \n",
    "                              delim_whitespace = True, \n",
    "                              skiprows         = 1, \n",
    "                              header           = None,\n",
    "                              index_col        = 0)\n",
    "    dist_matrix.columns = dist_matrix.index\n",
    "    \n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternativelly, load pairwise distances from newick file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_matrix_from_tree(newick_txt=None):\n",
    "    tree = ete3.Tree(newick_txt, format=1)\n",
    "\n",
    "    leaf_names = tree.get_leaf_names()\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if not node.is_leaf():\n",
    "            node.name = 'node_%i' % count\n",
    "\n",
    "    edges = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                edges.append((node.name,\n",
    "                              child.name,\n",
    "                              child.dist))\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges     =tuple(edges), \n",
    "                              directed  =False,\n",
    "                              edge_attrs=['weight']\n",
    "                             )\n",
    "    \n",
    "    patristic_distances     = np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                          target=leaf_names, \n",
    "                                                          weights='weight'))\n",
    "                                       \n",
    "    np.fill_diagonal(patristic_distances, 0.0)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =patristic_distances)\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match possibly co-evolving genes within a genome by looking for pairs minimzing wODR residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def match_copies(matrix1, matrix2, taxa1, taxa2):\n",
    "    \n",
    "    all_taxon_pairs           = pd.DataFrame()\n",
    "    all_taxon_pairs['taxon1'] = [re.sub('\\|\\d$', '', taxon, flags=re.M)\n",
    "                                for taxon in taxa1.taxon]\n",
    "    all_taxon_pairs['taxon2'] = [re.sub('\\|\\d$', '', taxon, flags=re.M)\n",
    "                                for taxon in taxa2.taxon]\n",
    "\n",
    "    triu_indices = np.triu_indices_from(matrix1, k=1)\n",
    "    condensed1   = matrix1.values[triu_indices]\n",
    "    condensed2   = matrix2.values[triu_indices]\n",
    "\n",
    "    model = Model(line)\n",
    "    data  = Data(condensed1, \n",
    "                 condensed2)\n",
    "    odr   = ODR(data, \n",
    "                model,\n",
    "                beta0=[np.std(condensed2) /\n",
    "                       np.std(condensed1)]\n",
    "               )\n",
    "\n",
    "    regression = odr.run()\n",
    "\n",
    "    residual_df = pd.DataFrame(columns=['x_taxon1',   'x_genome1', \n",
    "                                        'x_taxon2',   'x_genome2', \n",
    "\n",
    "                                        'y_taxon1',   'y_genome1', \n",
    "                                        'y_taxon2',   'y_genome2', \n",
    "\n",
    "                                        'x_residual', 'y_residual'],\n",
    "                               data=zip(matrix1.index[triu_indices[0]],        #x_taxon1\n",
    "                                        taxa1.iloc[triu_indices[0], 1].values, #x_genome1\n",
    "                                        matrix1.index[triu_indices[1]],        #x_taxon2\n",
    "                                        taxa1.iloc[triu_indices[1], 1].values, #x_genome2\n",
    "\n",
    "                                        matrix2.index[triu_indices[0]],        #y_taxon1\n",
    "                                        taxa2.iloc[triu_indices[0], 1].values, #y_genome1\n",
    "                                        matrix2.index[triu_indices[1]],        #y_taxon2\n",
    "                                        taxa2.iloc[triu_indices[1], 1].values, #y_genome2\n",
    "\n",
    "                                        abs(regression.delta),                 #x_residual\n",
    "                                        abs(regression.eps))                   #y_residual\n",
    "                              )\n",
    "    residual_df['combined_residual'] = residual_df.x_residual + residual_df.y_residual\n",
    "\n",
    "    within_genomes = ((residual_df.x_genome1 == residual_df.x_genome2) | \n",
    "                      (residual_df.y_genome1 == residual_df.y_genome2))\n",
    "\n",
    "    residual_df.drop(index  =residual_df.index[within_genomes], \n",
    "                     inplace=True)\n",
    "    \n",
    "    for genome in taxa1.genome[taxa1.genome.duplicated()].unique():\n",
    "    \n",
    "        matrix1_homologs = taxa1.loc[taxa1.genome==genome, \n",
    "                                     'taxon'].values\n",
    "        matrix2_homologs = taxa2.loc[taxa2.genome==genome, \n",
    "                                     'taxon'].values\n",
    "\n",
    "        homolog_combinations = pd.DataFrame(columns=['homolog1', \n",
    "                                                     'homolog2', \n",
    "                                                     'residual_sum'])\n",
    "        for homolog1, homolog2 in itertools.product(matrix1_homologs,\n",
    "                                                    matrix2_homologs):\n",
    "            tmp_df = residual_df.query('(x_taxon1 == @homolog1 | x_taxon2 == @homolog1) &'\n",
    "                                       '(y_taxon1 == @homolog2 | y_taxon2 == @homolog2)')\n",
    "\n",
    "            if not tmp_df.shape[0]:\n",
    "                continue\n",
    "\n",
    "            #\n",
    "            # remove \"|<num>\" sufix from taxon names to obtain original name\n",
    "            homolog1 = re.sub('\\|\\d$', \n",
    "                              '',\n",
    "                              homolog1, \n",
    "                              flags=re.M)\n",
    "            homolog2 = re.sub('\\|\\d$',\n",
    "                              '', \n",
    "                              homolog2, \n",
    "                              flags=re.M)\n",
    "\n",
    "            # add all residuals related to each pair of possibly co-evolving genes\n",
    "            #     within a single genome to a dataframe\n",
    "            homolog_combinations = homolog_combinations.append(\n",
    "                pd.Series(index=['homolog1', \n",
    "                                 'homolog2', \n",
    "                                 'residual_sum'],\n",
    "                          data =[homolog1, \n",
    "                                 homolog2, \n",
    "                                 tmp_df.combined_residual.sum()]), \n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "        homolog_combinations.sort_values('residual_sum', inplace=True)\n",
    "        best_pairs = set()\n",
    "        while homolog_combinations.shape[0]:\n",
    "            first_row = homolog_combinations.iloc[0]\n",
    "            best_pairs.add((first_row.homolog1, first_row.homolog2))\n",
    "            homolog_combinations = homolog_combinations.query(f'(homolog1 != \"{first_row.homolog1}\") & '\n",
    "                                                              f'(homolog2 != \"{first_row.homolog2}\")').copy()\n",
    "            \n",
    "        # drop all gene combinations where one is not each other's best pairing\n",
    "        for homolog1, homolog2 in best_pairs:\n",
    "            indices_to_drop = all_taxon_pairs.query(\n",
    "                '(taxon1 == @homolog1 & taxon2 != @homolog2) |'\n",
    "                '(taxon1 != @homolog1 & taxon2 == @homolog2)'\n",
    "            ).index\n",
    "\n",
    "            all_taxon_pairs.drop(index=indices_to_drop, \n",
    "                                inplace=True)\n",
    "\n",
    "            taxa1.drop(index  =indices_to_drop, \n",
    "                       inplace=True)\n",
    "            taxa2.drop(index  =indices_to_drop, \n",
    "                       inplace=True)\n",
    "    \n",
    "    matrix1 = matrix1.reindex(index  =taxa1.taxon, \n",
    "                              columns=taxa1.taxon, \n",
    "                              copy   =True)\n",
    "    matrix2 = matrix2.reindex(index  =taxa2.taxon, \n",
    "                              columns=taxa2.taxon, \n",
    "                              copy   =True)\n",
    "    \n",
    "    return(matrix1, taxa1, matrix2, taxa2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance distance matrices, duplicate rows/columns to reflect multiples copies in the compared gene families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def balance_matrices(matrix1, matrix2):\n",
    "\n",
    "    if gene_ids.value:\n",
    "        shared_genomes = np.intersect1d(matrix1.index,\n",
    "                                        matrix2.index)\n",
    "\n",
    "        matrix1 = matrix1.reindex(index  =shared_genomes,\n",
    "                                  columns=shared_genomes,\n",
    "                                  copy   =True)\n",
    "        matrix2 = matrix2.reindex(index  =shared_genomes,\n",
    "                                  columns=shared_genomes,\n",
    "                                  copy   =True)\n",
    "\n",
    "        return (matrix1, None,\n",
    "                matrix2, None)\n",
    "    \n",
    "    tmp_taxa = []\n",
    "    for index in matrix1.index:\n",
    "        genome, gene = re.search(parse_leaf, index).groups()\n",
    "        tmp_taxa.append([index, genome, gene])\n",
    "    taxa1 = pd.DataFrame(columns=['taxon', 'genome', 'gene'],\n",
    "                         data   =tmp_taxa)\n",
    "\n",
    "    tmp_taxa = []\n",
    "    for index in matrix2.index:\n",
    "        genome, gene = re.search(parse_leaf, index).groups()\n",
    "        tmp_taxa.append([index, genome, gene])\n",
    "    taxa2 = pd.DataFrame(columns=['taxon', 'genome', 'gene'],\n",
    "                         data=tmp_taxa)\n",
    "\n",
    "    shared_genomes = np.intersect1d(taxa1.genome.unique(), \n",
    "                                    taxa2.genome.unique())\n",
    "\n",
    "    taxa1 = taxa1[taxa1.genome.isin(shared_genomes)]\n",
    "    taxa2 = taxa2[taxa2.genome.isin(shared_genomes)]\n",
    "\n",
    "    if not taxa1.genome.is_unique or not taxa2.genome.is_unique:\n",
    "    \n",
    "        taxa1_frequency = taxa1.genome.value_counts() \n",
    "        taxa2_frequency = taxa2.genome.value_counts() \n",
    "\n",
    "        for genome in shared_genomes:\n",
    "            genome1_count = taxa1_frequency[genome]\n",
    "            genome2_count = taxa2_frequency[genome]\n",
    "\n",
    "            if genome1_count > 1:\n",
    "                #\n",
    "                # one of the matrices must be traversed in the inversed order to make sure an \n",
    "                #     all VS all combination is obtained. That is the reason of the \"iloc[::-1]\"\n",
    "                #     during the querying\n",
    "                tmp_df = taxa2.iloc[::-1].query('genome == @genome').copy()\n",
    "                for _ in range(genome1_count - 1):\n",
    "                    for index, row in tmp_df.iterrows():\n",
    "                        tmp_row = row.copy()\n",
    "                        tmp_row.taxon += f'|{_}'\n",
    "                        taxa2      = taxa2.append(tmp_row, ignore_index=True)\n",
    "\n",
    "                        reference_name = re.sub('\\|\\d+$', '', tmp_row.taxon, flags=re.M)\n",
    "                        matrix2[    tmp_row.taxon] = matrix2[    reference_name]\n",
    "                        matrix2.loc[tmp_row.taxon] = matrix2.loc[reference_name]\n",
    "\n",
    "\n",
    "            if genome2_count > 1:\n",
    "                #\n",
    "                # as we queried the other matrix in the reverse order, we traverse this one regularly\n",
    "                tmp_df = taxa1.query('genome == @genome').copy()\n",
    "                for _ in range(genome2_count - 1):\n",
    "                    for index, row in tmp_df.iterrows():\n",
    "                        tmp_row = row.copy()\n",
    "                        tmp_row.taxon += f'|{_}'\n",
    "                        taxa1 = taxa1.append(tmp_row, ignore_index=True)\n",
    "\n",
    "                        reference_name = re.sub('\\|\\d+$', '', tmp_row.taxon, flags=re.M)\n",
    "                        matrix1[    tmp_row.taxon] = matrix1[    reference_name]\n",
    "                        matrix1.loc[tmp_row.taxon] = matrix1.loc[reference_name]\n",
    "\n",
    "    #\n",
    "    # sort both taxa tables according to genomes for properly matching\n",
    "    taxa1.sort_values('genome', inplace=True)\n",
    "    taxa2.sort_values('genome', inplace=True)\n",
    "\n",
    "    taxa1.reset_index(drop=True, inplace=True)\n",
    "    taxa2.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    #\n",
    "    # match matrices index and column sorting as taxa tables\n",
    "    matrix1 = matrix1.reindex(index  =taxa1.taxon, \n",
    "                              columns=taxa1.taxon, \n",
    "                              copy   =True)\n",
    "    matrix2 = matrix2.reindex(index  =taxa2.taxon, \n",
    "                              columns=taxa2.taxon, \n",
    "                              copy   =True)\n",
    "    \n",
    "    if not taxa1.genome.is_unique or not taxa2.genome.is_unique:\n",
    "        matrix1, taxa1, matrix2, taxa2 = match_copies(matrix1, matrix2, taxa1, taxa2)\n",
    "    \n",
    "    return(matrix1, taxa1, \n",
    "           matrix2, taxa2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where the magic happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def assess_coevolution(matrix1, matrix2):\n",
    "\n",
    "    matrix1, taxa1, matrix2, taxa2 = balance_matrices(matrix1.copy(), \n",
    "                                                      matrix2.copy())\n",
    "\n",
    "    min_overlap = True\n",
    "    if       gene_ids.value and taxa1.genome.unique().shape[0] < min_taxa_overlap.value:\n",
    "        min_overlap = False\n",
    "    elif not gene_ids.value and               matrix1.shape[0] < min_taxa_overlap.value:\n",
    "        min_overlap = False\n",
    "\n",
    "    if not min_overlap:\n",
    "        print(f'Assessed matrices have less than {min_taxa_overlap.value} taxa overlap. '\n",
    "               'To change this behavior adjust overlap parameter.',\n",
    "              file=sys.stderr)\n",
    "        return([None, None])\n",
    "\n",
    "    condensed1 = squareform(matrix1.values, checks=False)\n",
    "    condensed2 = squareform(matrix2.values, checks=False)\n",
    "    \n",
    "    odr_weights = estimate_weights(condensed1, condensed2)\n",
    "    \n",
    "    regression = run_odr(condensed1, \n",
    "                         condensed2, \n",
    "                         *odr_weights)\n",
    "    \n",
    "    #\n",
    "    # calculate R^2 from wODR model.\n",
    "    mean_x = np.mean(condensed1)\n",
    "    mean_y = np.mean(condensed2)\n",
    "\n",
    "    mean_pred_x = regression.xplus.mean()\n",
    "    mean_pred_y = regression.y.mean()\n",
    "\n",
    "    x_SSres = sum(regression.delta**2)\n",
    "    y_SSres = sum(regression.eps  **2)\n",
    "    SSres   = x_SSres + y_SSres\n",
    "\n",
    "    x_SSreg = sum(\n",
    "        (regression.xplus - mean_pred_x)**2\n",
    "    )\n",
    "    y_SSreg = sum(\n",
    "        (regression.y     - mean_pred_y)**2\n",
    "    )\n",
    "    SSreg   = x_SSreg + y_SSreg\n",
    "\n",
    "    x_SStot = sum(\n",
    "        (condensed1 - mean_x)**2\n",
    "    )\n",
    "    y_SStot = sum(\n",
    "        (condensed2 - mean_y)**2\n",
    "    )\n",
    "    SStot   = x_SStot + y_SStot\n",
    "\n",
    "    r2 = 1 - SSres/SStot\n",
    "#     r2 = SSreg/SStot\n",
    "    \n",
    "    return(regression, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist1 = run_dist_matrix('/work/clusterEvo/distance_matrices/000284/000284')\n",
    "# dist2 = run_dist_matrix('/work/clusterEvo/distance_matrices/000302/000302')\n",
    "\n",
    "# regression, r2 = assess_coevolution(dist1, dist2)\n",
    "\n",
    "# regression.pprint()\n",
    "# print(f'\\nR**2 = {r2}')\n",
    "\n",
    "## Beta: [0.49615544]\n",
    "## Beta Std Error: [0.00033644]\n",
    "## Beta Covariance: [[1.99398167e-06]]\n",
    "## Residual Variance: 0.056766828371899364\n",
    "## Inverse Condition #: 1.0\n",
    "## Reason(s) for Halting:\n",
    "##   Sum of squares convergence\n",
    "##\n",
    "## R**2 = 0.8947962483462916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crappy notebook interface, but still an interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "evol_dist_source = widgets.Dropdown(\n",
    "    options    =[('',                       0       ), \n",
    "                 ('FASTA files',            'fasta' ), \n",
    "                 ('IQTree \".mldist\" files', 'matrix'), \n",
    "                 ('newick files',           'tree'  )],\n",
    "    disabled   =False,\n",
    "    indent     =False,\n",
    "    value      =0,\n",
    "    layout     ={'width':'auto'}\n",
    ")\n",
    "\n",
    "must_align = widgets.Checkbox(\n",
    "    value   =False,  \n",
    "    disabled=True,\n",
    "    indent  =False,\n",
    "    description='Provided FASTAS are not yet aligned',\n",
    "    layout     ={'width':'auto'}\n",
    ")\n",
    "\n",
    "gene_ids = widgets.Checkbox(\n",
    "    value   =False,  \n",
    "    disabled=False,\n",
    "    indent  =False,\n",
    "    description='Sequences are identified by genome only (all sequences from the same genome have the same name)',\n",
    "    layout     ={'width':'auto'}\n",
    ")\n",
    "\n",
    "min_taxa_overlap = widgets.IntText(value      =5, \n",
    "                                   indent     =False,\n",
    "                                   disabled   =False)\n",
    "\n",
    "genome_gene_sep = widgets.Dropdown(\n",
    "    options    =[('',                                     0  ), \n",
    "                 ('<genome>_<gene>', '_'), \n",
    "                 ('<genome>|<gene>', '|'), \n",
    "                 ('<genome>.<gene>', '.')],\n",
    "    disabled   =False,\n",
    "    indent     =True,\n",
    "    value      =0,\n",
    "    layout     ={'width':'auto'}\n",
    ")\n",
    "\n",
    "input_files = widgets.FileUpload(\n",
    "    accept  ='',   # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=True, # True to accept multiple files upload else False\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "def toggle_align_widgets(dropdown_source):\n",
    "    input_files.disabled = not dropdown_source.new\n",
    "    \n",
    "    if dropdown_source.new == 'fasta':\n",
    "        must_align.disabled = False\n",
    "    else:\n",
    "        must_align.disabled = True\n",
    "        must_align.value    = False\n",
    "    \n",
    "def toggle_genome_gene_sep(checkbox):\n",
    "    genome_gene_sep.disabled = checkbox.new\n",
    "    if checkbox.new:\n",
    "        genome_gene_sep.value = 0\n",
    "        \n",
    "def clear_uploads(*args):\n",
    "    input_files.value.clear()\n",
    "    input_files._counter = 0\n",
    "    \n",
    "clear_button = widgets.Button(description='Clear upload',\n",
    "                              button_style='warning',\n",
    "                              tooltip     ='Click to clear uploaded files')\n",
    "clear_button.on_click(clear_uploads)\n",
    "\n",
    "evol_dist_source.observe(toggle_align_widgets, names='value')\n",
    "gene_ids.observe(toggle_genome_gene_sep,       names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9421250007a74dd3855b5d83d8cf47f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Source of pairwise distances: '), Dropdown(layout=Layout(width='auto'), options=((…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6fb659066f412f843d43197777f085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Provided FASTAS are not yet aligned', disabled=True, indent=False, layout=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e008ef7f402c4e138801b9eb3c1c5721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Sequences are identified by genome only (all sequences from the same genome…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4a87dfa91242ac8debeedecd6173ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Genome and gene ids are separated by which character: '), Dropdown(layout=Layout(w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90213e9f6fe3454bbafefc472b1c6bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Minimum taxa containing both assessed gene families: '), IntText(value=5)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321bebf33e64428d8d9e161f666b4006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload', disabled=True, multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a231180cbb914b638905f5cc986bda5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Clear upload', style=ButtonStyle(), tooltip='Click to clear upload…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.HBox([widgets.Label('Source of pairwise distances: '), \n",
    "                      evol_dist_source]),\n",
    "        must_align,\n",
    "        gene_ids,\n",
    "        widgets.HBox([widgets.Label('Genome and gene ids are separated by which character: '),\n",
    "                      genome_gene_sep]),\n",
    "        \n",
    "        widgets.HBox([widgets.Label('Minimum taxa containing both assessed gene families: '),\n",
    "                      min_taxa_overlap]),\n",
    "        \n",
    "        input_files,\n",
    "        clear_button,\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing provided data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not input_files._counter > 1:\n",
    "    raise ValueError('You must upload at least two files!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dist_matrices = []\n",
    "group_names   = []\n",
    "\n",
    "if evol_dist_source.value == 'tree':\n",
    "    for file_name, file_itself in input_files.value.items():\n",
    "        dist_matrices.append( get_matrix_from_tree(file_itself['content'].decode('utf-8')) )\n",
    "        group_names.append( file_name )\n",
    "        \n",
    "elif evol_dist_source.value == 'matrix':\n",
    "    for file_name, file_itself in input_files.value.items():\n",
    "        dist_matrices.append( load_matrix(BytesIO(file_itself['content'])) )\n",
    "        group_names.append( file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if   genome_gene_sep.value == '_':\n",
    "    parse_leaf = re.compile('^(GC[AF]_\\d+(?:\\.\\d)?)[_|](.*)$')\n",
    "elif genome_gene_sep.value == '|':\n",
    "    parse_leaf = re.compile('^(\\S+?)\\|(\\S+)$')\n",
    "elif genome_gene_sep.value == '.':\n",
    "    parse_leaf = re.compile('^(\\d+?)\\.(.*)$')\n",
    "    \n",
    "if min_taxa_overlap.value < 2:\n",
    "    min_taxa_overlap.value = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.49615582]), 0.8947960994077019)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.beta, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000302.mldist', '000284.mldist']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: []\n",
       " Index: [], None, Empty DataFrame\n",
       " Columns: []\n",
       " Index: [], None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = dist_matrices[0].copy()\n",
    "m2 = dist_matrices[1].copy()\n",
    "\n",
    "balance_matrices(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = assess_coevolution(m2, m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yeah' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-2c5fcb951e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myeah\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'yeah' is not defined"
     ]
    }
   ],
   "source": [
    "yeah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
